{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import math\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dec_2016 = pd.read_csv('data/raw_data/Video_Games_Sales_as_at_22_Dec_2016.csv')\n",
    "jan_2017 = pd.read_csv('data/raw_data/Video_Game_Sales_as_of_Jan_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' Read all the csv's into a list. '''\n",
    "year_csv = {}\n",
    "for csv in glob.iglob('data/time_series_data/*.csv'):\n",
    "    thing = csv.split(\"/\")\n",
    "    year = thing[2].split(\".\")[0]\n",
    "    year_csv[year] = csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def total_sales_for_year(year, sales_region):\n",
    "    total_sales = 0\n",
    "    for k in range(len(dec_2016)):\n",
    "        this_year = dec_2016.iloc[k]['Year_of_Release']\n",
    "        if not math.isnan(this_year) and str(int(this_year)) == year:\n",
    "            total_sales += float(dec_2016.iloc[k][sales_region])\n",
    "            \n",
    "    for k in range(len(jan_2017)):\n",
    "        this_year = jan_2017.iloc[k]['Year_of_Release']\n",
    "        if not math.isnan(this_year) and str(int(this_year)) == year:\n",
    "            total_sales += float(jan_2017.iloc[k][sales_region])\n",
    "    return total_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' Returns a mapping of each year to the number of sales of games of the given feature in the given region.\n",
    "    Calculates number of sales normalized for that year if normalize is True - default False. '''\n",
    "def calc_sales_for_feature(year_csv, feature, feature_value, sales_region, normalize):\n",
    "    sales = {}\n",
    "    \n",
    "    for k in range(len(dec_2016)):\n",
    "        feat = dec_2016.iloc[k][feature]\n",
    "        year = dec_2016.iloc[k]['Year_of_Release']\n",
    "        if math.isnan(year):\n",
    "            continue\n",
    "        \n",
    "        if year not in sales.keys():\n",
    "            sales[int(year)] = 0.\n",
    "        if feat == feature_value:\n",
    "            sales[year] += dec_2016.iloc[k][sales_region]\n",
    "\n",
    "    for k in range(len(jan_2017)):\n",
    "        feat = jan_2017.iloc[k][feature]\n",
    "        year = jan_2017.iloc[k]['Year_of_Release']\n",
    "        if math.isnan(year):\n",
    "            continue \n",
    "        \n",
    "        if year not in sales.keys():\n",
    "            sales[int(year)] = 0.\n",
    "        if feat == feature_value:\n",
    "            sales[year] += jan_2017.iloc[k][sales_region]\n",
    "    \n",
    "    # Normalize sales by the total sales for all games in the given year.\n",
    "    if normalize:\n",
    "        for year in sales.keys():\n",
    "            sales[year] /= total_sales_for_year(str(year), sales_region)\n",
    "    \n",
    "    return sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_success_data(X_label, Y_label):\n",
    "    # Get list of unique genres from datasets.\n",
    "    x_values = []\n",
    "#    for genre in dec_2016['Genre']:\n",
    "    for x in dec_2016[X_label]:\n",
    "        if x not in x_values:\n",
    "            x_values.append(x)        \n",
    "    for x in jan_2017[X_label]:\n",
    "        if x not in x_values:\n",
    "            x_values.append(x)\n",
    "\n",
    "    # Aggregate yearly global sales for each genre, normalized and unnormalized.\n",
    "    for x in x_values:\n",
    "#        sales = calc_sales_for_feature(year_csv, 'Genre', genre, 'Global_Sales', False)\n",
    "        sales = calc_sales_for_feature(year_csv, X_label, x, Y_label, False)\n",
    "        sales_norm = calc_sales_for_feature(year_csv, X_label, x, Y_label, True)\n",
    "\n",
    "        # Save the aggregated sales to csv's (because this takes forever to run)\n",
    "        pd.DataFrame.from_dict(sales, orient='index').to_csv('data/time_series_data/aggregated_sales/' + x + '.csv')\n",
    "        pd.DataFrame.from_dict(sales_norm, orient='index').to_csv('data/time_series_data/aggregated_sales/' + x + '_norm.csv')\n",
    "\n",
    "        # Plot the aggregated sales against years.\n",
    "        plt.scatter(sales.keys(), sales.values())\n",
    "        plt.title(x)\n",
    "        plt.show()\n",
    "        plt.scatter(sales_norm.keys(), sales_norm.values())\n",
    "        plt.title(x + ' - normalized')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonydepalatis/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 43]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-1dde9cabe0e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/time_series_data/aggregated_sales/Action.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtransformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/anthonydepalatis/anaconda/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anthonydepalatis/anaconda/lib/python2.7/site-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=np.float64,\n\u001b[0;32m-> 1173\u001b[0;31m                          order=\"C\")\n\u001b[0m\u001b[1;32m   1174\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anthonydepalatis/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anthonydepalatis/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 181\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 43]"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "df = pd.read_csv('data/time_series_data/aggregated_sales/Action.csv')\n",
    "\n",
    "transformed = clf.fit_transform(df['Unnamed: 0'], df['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
